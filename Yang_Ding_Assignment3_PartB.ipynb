{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR 891: Programming Assignment #3\n",
    "## Part B: \n",
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jing/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train and test data separtely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,random_state=42)\n",
    "X_train = train_data.data\n",
    "y_train = train_data.target\n",
    "test_data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "X_test = test_data.data\n",
    "y_test = test_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer train and test data separtely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "X_train = list(map(lambda text: (' '.join(lemmatizer.lemmatize(w.lower()) for w in nltk.word_tokenize(text.lower()))), X_train))\n",
    "\n",
    "X_test = list(map(lambda text: (' '.join(lemmatizer.lemmatize(w.lower()) for w in nltk.word_tokenize(text.lower()))), X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if words are lemmatized (data list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257\n",
      "from : sd345 @ city.ac.uk ( michael collier ) subject : converting image to hp laserjet iii ? nntp-posting-host : hampton organization : the city university line : 14 doe anyone know of a good way ( standard pc application/pd utility ) to convert tif/img/tga file into laserjet iii format . we would also like to do the same , converting to hpgl ( hp plotter ) file . please email any response . is this the correct group ? thanks in advance . michael . -- michael collier ( programmer ) the computer unit , email : m.p.collier @ uk.ac.city the city university , tel : 071 477-8000 x3769 london , fax : 071 477-8565 ec1v 0hb .\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 6 Multinomial NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Pipeline for Hyperparameter Tuning & Feature Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_multinomialNB = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   30.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.981391\n",
      "clf__alpha: 0.001\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n",
      "\n",
      "\n",
      "CPU times: user 3.75 s, sys: 614 ms, total: 4.36 s\n",
      "Wall time: 31.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "    'clf__alpha': [0.0001, 0.001, 0.1, 1.0, 1.5, 2.0],\n",
    "}\n",
    "\n",
    "\n",
    "clf_multinomial_cv = GridSearchCV(text_clf_multinomialNB, param_grid, scoring='f1_micro', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf_multinomial_cv = clf_multinomial_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_clf_multinomial = clf_multinomial_cv.best_params_\n",
    "\n",
    "print(\"\\nBest Score: %f\" % clf_multinomial_cv.best_score_)\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, params_optimal_clf_multinomial[param_name]))\n",
    "    \n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('clf', MultinomialNB(alpha=0.001))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=False)),\n",
    "        ('clf', MultinomialNB(alpha=0.001)),\n",
    "    ])\n",
    "\n",
    "multinomialNB_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "\n",
      "Test Accuracy:  0.9387483355525965\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[296   4   5  14]\n",
      " [  5 367  15   2]\n",
      " [  3  17 363  13]\n",
      " [  5   2   7 384]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       319\n",
      "           1       0.94      0.94      0.94       389\n",
      "           2       0.93      0.92      0.92       396\n",
      "           3       0.93      0.96      0.95       398\n",
      "\n",
      "    accuracy                           0.94      1502\n",
      "   macro avg       0.94      0.94      0.94      1502\n",
      "weighted avg       0.94      0.94      0.94      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", multinomialNB_clf.score(X_train, y_train))\n",
    "\n",
    "print(\"\\nTest Accuracy: \", multinomialNB_clf.score(X_test, y_test))\n",
    "\n",
    "y_test_predicted = multinomialNB_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 7: Support Vector Machine (LinearSVC)\n",
    "### Building a Pipeline for Hyperparameter Tuning & Feature Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linearsvc = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LinearSVC(loss='hinge', random_state=42)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for LinearSVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.977403\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "clf__C: 5\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n",
      "CPU times: user 2min 6s, sys: 2.81 s, total: 2min 9s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "    'clf__C': [0.1, 1, 5, 10],\n",
    "}\n",
    "\n",
    "svm_linearsvc_cv = GridSearchCV(svm_linearsvc, param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "svm_linearsvc_cv = svm_linearsvc_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\nBest Score: %f\" % svm_linearsvc_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, svm_linearsvc_cv.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Optimal LinearSVC Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 s, sys: 54.7 ms, total: 2.69 s\n",
      "Wall time: 2.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LinearSVC(C=5, loss='hinge', random_state=42))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_linearsvc = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words= 'english', ngram_range=(1, 2), binary=False)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LinearSVC(loss='hinge', C=5, random_state=42)),\n",
    "    ])\n",
    "\n",
    "svm_linearsvc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate LinearSVC Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "\n",
      "Test Accuracy:  0.9320905459387483\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[275   8   8  28]\n",
      " [  4 377   6   2]\n",
      " [  6  24 364   2]\n",
      " [  4   7   3 384]]\n",
      "\n",
      "Test Precision = 0.932091\n",
      "\n",
      "Test Recall = 0.932091\n",
      "\n",
      "Test F1 Score = 0.932091\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90       319\n",
      "           1       0.91      0.97      0.94       389\n",
      "           2       0.96      0.92      0.94       396\n",
      "           3       0.92      0.96      0.94       398\n",
      "\n",
      "    accuracy                           0.93      1502\n",
      "   macro avg       0.93      0.93      0.93      1502\n",
      "weighted avg       0.93      0.93      0.93      1502\n",
      "\n",
      "CPU times: user 1.37 s, sys: 20.9 ms, total: 1.39 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_test_predicted = svm_linearsvc.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy: \", svm_linearsvc.score(X_train, y_train))\n",
    "\n",
    "print(\"\\nTest Accuracy: \", np.mean(y_test_predicted == y_test))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average='micro') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest Recall = %f\" % recall_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 8: Support Vector Machine (SVC with RBF Kernel)\n",
    "### Building a Pipeline for Hyperparameter Tuning & Feature Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_svc_rbf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SVC(kernel='rbf')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for SVC (RBF Kernel) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.977402\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "clf__C: 100\n",
      "clf__gamma: 0.01\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n",
      "CPU times: user 15.7 s, sys: 972 ms, total: 16.6 s\n",
      "Wall time: 6min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "    'clf__C': [0.1, 1, 10, 100],\n",
    "    'clf__gamma': [0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "svm_svc_rbf_cv = GridSearchCV(svm_svc_rbf, param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "svm_svc_rbf_cv = svm_svc_rbf_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Score: %f\" % svm_svc_rbf_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, svm_svc_rbf_cv.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Optimal SVC (RBF Kernel) Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 71.2 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', SVC(C=100, gamma=0.01, random_state=42))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_svc_rbf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=False)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SVC(kernel='rbf', C=100, gamma=0.01, random_state=42)),\n",
    "    ])\n",
    "\n",
    "svm_svc_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate SVC (RBF Kernel) Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "\n",
      "Test Accuracy:  0.9274300932090546\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[272   9   7  31]\n",
      " [  1 376   8   4]\n",
      " [  5  26 362   3]\n",
      " [  4   8   3 383]]\n",
      "\n",
      "Test Precision = 0.927430\n",
      "\n",
      "Test Recall = 0.927430\n",
      "\n",
      "Test F1 Score = 0.927430\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.91       319\n",
      "           1       0.90      0.97      0.93       389\n",
      "           2       0.95      0.91      0.93       396\n",
      "           3       0.91      0.96      0.94       398\n",
      "\n",
      "    accuracy                           0.93      1502\n",
      "   macro avg       0.93      0.92      0.93      1502\n",
      "weighted avg       0.93      0.93      0.93      1502\n",
      "\n",
      "CPU times: user 12 s, sys: 69.5 ms, total: 12.1 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_test_predicted = svm_svc_rbf.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy: \", svm_svc_rbf.score(X_train, y_train))\n",
    "      \n",
    "print(\"\\nTest Accuracy: \", np.mean(y_test_predicted == y_test))\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average='micro') \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest Recall = %f\" % recall_test)\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average='micro')\n",
    "print(\"\\nTest F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-5) Between linear SVM and nonlinear SVM, which classifier performed the best on test data? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Linear SVM has slightly better performance compared to nonlinear SVM model because text classification data are linearly separable. Other than that, the LinearSVC is faster than the SVC with RBF Kernel. Because it scales linearly with the number of training instances and the number of features, unlike the kernelized SVM that solves the dual problem whose complexity is quadratic (at best) with the number of instances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
