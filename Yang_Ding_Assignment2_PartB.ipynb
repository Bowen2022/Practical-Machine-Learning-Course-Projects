{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR 891: Programming Assignment #2\n",
    "## Part B: \n",
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jing/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jing/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data & create dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('NewsRealCOVID-19-05.csv', header = 0)\n",
    "df2 = pd.read_csv('NewsFakeCOVID-19-05.csv', header = 0)\n",
    "\n",
    "df1['label'] = 1\n",
    "df2['label'] = 0\n",
    "\n",
    "df_all = pd.concat([df1, df2], ignore_index=True) \n",
    "df = df_all.loc[:, ['content', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experts warn most states that are reopening st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a new study finds an increase in screen time d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scientists around the world are working on a n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coronaviruses cause respiratory illnesses so t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medical experts are studying if remdesivir can...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  label\n",
       "0  experts warn most states that are reopening st...      1\n",
       "1  a new study finds an increase in screen time d...      1\n",
       "2  scientists around the world are working on a n...      1\n",
       "3  coronaviruses cause respiratory illnesses so t...      1\n",
       "4  medical experts are studying if remdesivir can...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information on the pandas data frame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2162 entries, 0 to 2161\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  1522 non-null   object\n",
      " 1   label    2162 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 33.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if there are any null values in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the rows containing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['content'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the data:  (1522, 2)\n",
      "\n",
      "No. of Rows: 1522\n",
      "No. of Columns: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of the data: \", df.shape)\n",
    "\n",
    "no_of_rows = df.shape[0]\n",
    "no_of_columns = df.shape[1]\n",
    "\n",
    "print(\"\\nNo. of Rows: %d\" % no_of_rows)\n",
    "print(\"No. of Columns: %d\" % no_of_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       content\n",
       "label         \n",
       "0          125\n",
       "1         1397"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jing/opt/anaconda3/envs/am_keras_tf/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = df.label.value_counts()\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.barplot(label_counts.index, label_counts.values, alpha=0.9)\n",
    "\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.xlabel('label', fontsize=12)\n",
    "plt.ylabel('Counts', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the news length and the classes (fake/real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.0</td>\n",
       "      <td>441.048000</td>\n",
       "      <td>124.378251</td>\n",
       "      <td>36.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1397.0</td>\n",
       "      <td>473.110236</td>\n",
       "      <td>73.065309</td>\n",
       "      <td>64.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>502.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count        mean         std   min    25%    50%    75%    max\n",
       "label                                                                  \n",
       "0       125.0  441.048000  124.378251  36.0  488.0  492.0  494.0  500.0\n",
       "1      1397.0  473.110236   73.065309  64.0  489.0  492.0  495.0  502.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column \"length\" the stores the length of the content on each row \n",
    "df['length'] = df['content'].map(lambda content: len(content))\n",
    "\n",
    "df.groupby('label').length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize length distribution by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'0'}>,\n",
       "       <AxesSubplot:title={'center':'1'}>], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a length threshold to visualize the distribution of length per class\n",
    "\n",
    "threshold = 1800\n",
    "News_subset = df[df.length < threshold]\n",
    "News_subset.hist(column='length', by='label', bins=100, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation from the EDA\n",
    "We observe that only **8.21%** news are fake.\n",
    "\n",
    "Also there are some outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text normalization by lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['content_lemmatized'] = df['content'].map(lambda text: ' '.join(lemmatizer.lemmatize(w) for w in nltk.word_tokenize(text.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a seperate feature set (data matrix X) and target (1D array Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Matrix (X) Shape:  (1522,)\n",
      "Label array (y) Shape:  (1522,)\n",
      "\n",
      "Data Matrix (X) Type:  object\n",
      "Label array (y) Type:  int64\n"
     ]
    }
   ],
   "source": [
    "X = df[\"content_lemmatized\"] # Data frame containing the target \n",
    "y = df['label'] # Data frame containing the features excluding the target\n",
    "\n",
    "'''\n",
    "Convert X & y into Arrays\n",
    "Use the NumPy asarray() method to convert the Pandas data frame object X and y into numpy arrays.\n",
    "'''\n",
    "X = np.asarray(X) # Data Matrix containing all features excluding the target\n",
    "y = np.asarray(y) # 1D target array\n",
    "\n",
    "print(\"Data Matrix (X) Shape: \", X.shape)\n",
    "print(\"Label array (y) Shape: \", y.shape)\n",
    "\n",
    "print(\"\\nData Matrix (X) Type: \", X.dtype)\n",
    "print(\"Label array (y) Type: \", y.dtype)\n",
    "\n",
    "# # Read a random News from X\n",
    "# print(\"\\nA random News:\\n\")\n",
    "# print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the dataset into training & test subsets: 80% training & 20% test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 Multinomial NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_multinomialNB = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.977987\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "clf__alpha: 0.1\n",
      "vect__ngram_range: (1, 1)\n",
      "vect__stop_words: 'english'\n",
      "\n",
      "\n",
      "CPU times: user 493 ms, sys: 119 ms, total: 612 ms\n",
      "Wall time: 5.39 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    5.3s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "    'clf__alpha': [0.0001, 0.001, 0.1, 1.0, 1.5, 2.0],\n",
    "}\n",
    "\n",
    "clf_multinomial_cv = GridSearchCV(text_clf_multinomialNB, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf_multinomial_cv = clf_multinomial_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_clf_multinomial = clf_multinomial_cv.best_params_\n",
    "\n",
    "print(\"\\nBest Score: %f\" % clf_multinomial_cv.best_score_)\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, params_optimal_clf_multinomial[param_name]))\n",
    "    \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(stop_words='english')),\n",
       "                ('clf', MultinomialNB(alpha=0.1))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 1), binary=False)),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "multinomialNB_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9508196721311475\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[ 13  11]\n",
      " [  4 277]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.76      0.54      0.63        24\n",
      "        Real       0.96      0.99      0.97       281\n",
      "\n",
      "    accuracy                           0.95       305\n",
      "   macro avg       0.86      0.76      0.80       305\n",
      "weighted avg       0.95      0.95      0.95       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: \", multinomialNB_clf.score(X_test, y_test))\n",
    "\n",
    "y_test_predicted = multinomialNB_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = [\"Fake\", \"Real\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 Multinomial NB (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_multinomialNB_tfidf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.968246\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "clf__alpha: 0.001\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n",
      "\n",
      "\n",
      "CPU times: user 499 ms, sys: 45.7 ms, total: 545 ms\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "    'clf__alpha': [0.001, 0.1, 1.0, 1.5],\n",
    "}\n",
    "\n",
    "clf_multinomial_tfidf_cv = GridSearchCV(text_clf_multinomialNB_tfidf, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf_multinomial_tfidf_cv = clf_multinomial_tfidf_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "params_optimal_clf_multinomial_tfidf = clf_multinomial_tfidf_cv.best_params_\n",
    "\n",
    "print(\"\\nBest Score: %f\" % clf_multinomial_tfidf_cv.best_score_)\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, params_optimal_clf_multinomial_tfidf[param_name]))\n",
    "    \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB(alpha=0.001))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf_tfidf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=False)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB(alpha=0.001)),\n",
    "    ])\n",
    "\n",
    "multinomialNB_clf_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9377049180327869\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[  8  16]\n",
      " [  3 278]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.73      0.33      0.46        24\n",
      "        Real       0.95      0.99      0.97       281\n",
      "\n",
      "    accuracy                           0.94       305\n",
      "   macro avg       0.84      0.66      0.71       305\n",
      "weighted avg       0.93      0.94      0.93       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: \", multinomialNB_clf_tfidf.score(X_test, y_test))\n",
    "\n",
    "y_test_predicted = multinomialNB_clf_tfidf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = [\"Fake\", \"Real\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4: Multivariate Bernoulli NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_bernoulliNB = Pipeline([\n",
    "        ('vect', CountVectorizer(binary=True)),\n",
    "        ('clf', BernoulliNB()),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.973703\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "clf__alpha: 0.1\n",
      "vect__ngram_range: (1, 1)\n",
      "vect__stop_words: 'english'\n",
      "\n",
      "\n",
      "CPU times: user 274 ms, sys: 15.3 ms, total: 289 ms\n",
      "Wall time: 3.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "    'clf__alpha': [0.001, 0.1, 1.0, 1.5],\n",
    "}\n",
    "\n",
    "clf_bernoulli_cv = GridSearchCV(text_clf_bernoulliNB, param_grid, scoring='f1', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "clf_bernoulli_cv = clf_bernoulli_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_clf_bernoulli = clf_bernoulli_cv.best_params_\n",
    "\n",
    "print(\"\\nBest Score: %f\" % clf_bernoulli_cv.best_score_)\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, params_optimal_clf_bernoulli[param_name]))\n",
    "    \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(binary=True, stop_words='english')),\n",
       "                ('clf', BernoulliNB(alpha=0.1))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulliNB_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1,1), binary=True)),\n",
    "        ('clf', BernoulliNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "bernoulliNB_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9442622950819672\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[ 11  13]\n",
      " [  4 277]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.73      0.46      0.56        24\n",
      "        Real       0.96      0.99      0.97       281\n",
      "\n",
      "    accuracy                           0.94       305\n",
      "   macro avg       0.84      0.72      0.77       305\n",
      "weighted avg       0.94      0.94      0.94       305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: \", bernoulliNB_clf.score(X_test, y_test))\n",
    "\n",
    "y_test_predicted = bernoulliNB_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = [\"Fake\", \"Real\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: KNN using Count vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorization for test features. Note that the code below as provides the TF-IDF vectorization which will be directly used to evaluate TF-IDF KNN model later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of Vocabulary:  7481\n",
      "\n",
      "Vectorized Training Data Matrix Dimension:  (1217, 7481)\n",
      "\n",
      "Type of the Vectorized Training Data Matrix: \n",
      "<class 'numpy.matrix'>\n",
      "\n",
      "Vectorized Test Data Matrix Dimension:  (305, 7481)\n",
      "(1217, 7481)\n",
      "\n",
      "Vectorized Test Data Matrix (TF-IDF) Dimension:  (305, 7481)\n",
      "\n",
      "Vectorized Training Data: Row 1, Columns 1 - 20:  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "Vectorized (TF-IDF) Training Data: Row 1, Columns 1 - 20:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Depending on the problem scenario, there are various ways of creating the count vectorizer object\n",
    "'''\n",
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2))\n",
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english')\n",
    "#count_vect = CountVectorizer(lowercase=True, stop_words='english', binary=True)\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "\n",
    "\n",
    "# Create a matrix representation of the documents\n",
    "# Each row represents a single document\n",
    "# Each column represents the term frequecy for each feature\n",
    "X_train_vectorized_features = count_vect.fit_transform(X_train).todense()\n",
    "\n",
    "print(\"\\nSize of Vocabulary: \", len(count_vect.vocabulary_))\n",
    "\n",
    "\n",
    "print(\"\\nVectorized Training Data Matrix Dimension: \", X_train_vectorized_features.shape)\n",
    "\n",
    "print(\"\\nType of the Vectorized Training Data Matrix: \")\n",
    "print(type(X_train_vectorized_features))\n",
    "\n",
    "\n",
    "# Transform documents to document-term matrix.\n",
    "# Extract token counts out of raw text documents using the vocabulary fitted with fit \n",
    "# or the one provided to the constructor.\n",
    "X_test_vectorized_features = count_vect.transform(X_test).todense()\n",
    "print(\"\\nVectorized Test Data Matrix Dimension: \", X_test_vectorized_features.shape)\n",
    "\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_vectorized_features_tfidf = tfidf_transformer.fit_transform(X_train_vectorized_features).todense()\n",
    "print(X_train_vectorized_features_tfidf.shape)\n",
    "\n",
    "\n",
    "X_test_vectorized_features_tfidf = tfidf_transformer.transform(X_test_vectorized_features).todense()\n",
    "print(\"\\nVectorized Test Data Matrix (TF-IDF) Dimension: \", X_test_vectorized_features_tfidf.shape)\n",
    "\n",
    "\n",
    "print(\"\\nVectorized Training Data: Row 1, Columns 1 - 20: \", X_train_vectorized_features[0, 0:20])\n",
    "print(\"\\nVectorized (TF-IDF) Training Data: Row 1, Columns 1 - 20: \", X_train_vectorized_features_tfidf[0, 0:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized (train & test) data for performng KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized the data \n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train_vectorized_features)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train_vectorized_features)\n",
    "X_test = scaler.transform(X_test_vectorized_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.920293\n",
      "Optimal Hyperparameter Values:  {'n_neighbors': 5, 'p': 100, 'weights': 'distance'}\n",
      "\n",
      "\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "param_grid = {'n_neighbors': [ 5, 7, 9, 11], 'p': [2, 3, 4, 100], 'weights': [\"uniform\", \"distance\"]}\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "knn_cv = GridSearchCV(knn_clf, param_grid, scoring='f1_micro', cv=5, verbose=1, n_jobs=-1)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_knn = knn_cv.best_params_\n",
    "\n",
    "print(\"Best Score: %f\" % knn_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_knn)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9991783073130649\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "knn = KNeighborsClassifier(**params_optimal_knn)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = knn.predict(X_train)\n",
    "\n",
    "train_accuracy_knn = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy:  0.9311475409836065\n",
      "\n",
      "No. of correct predictions (Test): 284/305\n",
      "\n",
      "Confusion Matrix (Test Data):\n",
      " [[  5  19]\n",
      " [  2 279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.71      0.21      0.32        24\n",
      "        Real       0.94      0.99      0.96       281\n",
      "\n",
      "    accuracy                           0.93       305\n",
      "   macro avg       0.83      0.60      0.64       305\n",
      "weighted avg       0.92      0.93      0.91       305\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The accuracy of the model\n",
    "test_accuracy_knn = knn.score(X_test, y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_knn)\n",
    "\n",
    "\n",
    "# No. of Correct Predictions\n",
    "y_test_predicted = knn.predict(X_test)\n",
    "print(\"\\nNo. of correct predictions (Test): %d/%d\" % (np.sum(y_test_predicted == y_test), len(y_test)))\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_test_predicted, target_names = [\"Fake\", \"Real\"]))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5: KNN using TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF vectorization for test features (reweight features), it has been done before as mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized (train & test) data for performng KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized the data \n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train_vectorized_features_tfidf)\n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train_vectorized_features_tfidf)\n",
    "X_test = scaler.transform(X_test_vectorized_features_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.921116\n",
      "Optimal Hyperparameter Values:  {'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "param_grid = {'n_neighbors': [2, 3, 4, 5], 'p': [1, 2, 3, 100], 'weights': [\"uniform\", \"distance\"]}\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "knn_cv = GridSearchCV(knn_clf, param_grid, scoring='f1_micro', cv=5, verbose=1, n_jobs=-1)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "params_optimal_knn = knn_cv.best_params_\n",
    "\n",
    "print(\"Best Score: %f\" % knn_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal_knn)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.9991783073130649\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "knn = KNeighborsClassifier(**params_optimal_knn)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_train_predicted = knn.predict(X_train)\n",
    "\n",
    "train_accuracy_knn = np.mean(y_train_predicted == y_train)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy:  0.9377049180327869\n",
      "\n",
      "No. of correct predictions (Test): 286/305\n",
      "\n",
      "Confusion Matrix (Test Data):\n",
      " [[  5  19]\n",
      " [  0 281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      0.21      0.34        24\n",
      "        Real       0.94      1.00      0.97       281\n",
      "\n",
      "    accuracy                           0.94       305\n",
      "   macro avg       0.97      0.60      0.66       305\n",
      "weighted avg       0.94      0.94      0.92       305\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 8.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The accuracy of the model\n",
    "test_accuracy_knn = knn.score(X_test, y_test)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_knn)\n",
    "\n",
    "\n",
    "# No. of Correct Predictions\n",
    "y_test_predicted = knn.predict(X_test)\n",
    "print(\"\\nNo. of correct predictions (Test): %d/%d\" % (np.sum(y_test_predicted == y_test), len(y_test)))\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "# Classification report \n",
    "\n",
    "print(classification_report(y_test, y_test_predicted, target_names = [\"Fake\", \"Real\"]))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-2) Which classifier model performed the best (high precision & recall for thefake news class)? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results from Multinominal NB, Multinominal NB (TF-IDF Features), Multivariate Bernoulli NB, K-NN (count vectorization) and KNN (TF-IDF Features), we found that the **Multinomial NB model** has the **best** precision & recall for the fake news class, and it has the best test accuracy as well. \n",
    "\n",
    "Multinominal NB (TF-IDF Features) has poorer performance might be caused by wrongly reduced weight on the \"key\" words appearing in all fake news samples. In this example, the frequency of words appearing in the documents might be the key to acquire better model performance. While Multivariate Bernoulli NB that accounts for categorical feature (binary valued) only consider the word occurs in the document and word does not occur in the document, but not the frequency of the word. So, Bernoulli has lower accuracy compared to Multinomial NB that accounted the frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-3) Why is the performance (precision & recall) of the true/real class higher thanthe fake class? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the bar chart of class distribution, the fake news (N=125) has much lesser samples than real news (N=1397). That is the main reason why the real class has higher precision and recall than the fake class because it has much more data to better train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-4) Did K-NN outperform the Nave Bayes models? Would you use K-NN for this type of text classification problem? Why or why not? Justify?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both KNN using count or TF-IDF vectorizations did not outperform the NB models. We would not recommend using KNN models for this text classification problem because it takes longer time to perform and ends up with lower test accuracy then NB models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
