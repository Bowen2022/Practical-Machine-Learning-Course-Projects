{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGR 891: Programming Assignment #1\n",
    "# Part B: \n",
    "## Pre-Processing\n",
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Reshape Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of Training Samples:  (50000, 3072)\n",
      "Shape of Training Labels:  (50000, 1)\n",
      "\n",
      "Shape of Testing Samples:  (10000, 3072)\n",
      "Shape of Testing Labels:  (10000, 1)\n",
      "uint8\n",
      "uint8\n",
      "uint8\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "## Directly load this dataset using the Keras API:\n",
    "\n",
    "(X_train_cifar, y_train_cifar), (X_test_cifar, y_test_cifar) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "X_train_cifar = X_train_cifar.reshape((X_train_cifar.shape[0], 3072))\n",
    "X_test_cifar = X_test_cifar.reshape((X_test_cifar.shape[0], 3072))\n",
    "\n",
    "\n",
    "print(\"\\nShape of Training Samples: \", X_train_cifar.shape)\n",
    "print(\"Shape of Training Labels: \", y_train_cifar.shape)\n",
    "\n",
    "print(\"\\nShape of Testing Samples: \", X_test_cifar.shape)\n",
    "print(\"Shape of Testing Labels: \", y_test_cifar.shape)\n",
    "print(X_train_cifar.dtype)\n",
    "print(y_train_cifar.dtype)\n",
    "print(X_test_cifar.dtype)\n",
    "print(y_test_cifar.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert the label data into a 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# convert the label data into a 1D array\n",
    "y_train_cifar = y_train_cifar.ravel()\n",
    "y_test_cifar = y_test_cifar.ravel()\n",
    "print(y_train_cifar.shape)\n",
    "print(y_test_cifar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarized the data by using min-max method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale the data by dividing 255\n",
    "X_train_cifar = X_train_cifar/255.0\n",
    "X_test_cifar = X_test_cifar/255.0\n",
    "# Display the minimum and maximum values of the scaled data\n",
    "X_train_cifar.min(), X_train_cifar.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train KNN model and get train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy:  0.53512\n",
      "Wall time: 44min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, p =1, n_jobs= -1)\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X_train_cifar, y_train_cifar)\n",
    "\n",
    "# Compute accuracy on the training set\n",
    "y_train_predicted = knn.predict(X_train_cifar)\n",
    "\n",
    "train_accuracy_knn = np.mean(y_train_predicted == y_train_cifar)\n",
    "print(\"\\nTraining Accuracy: \", train_accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training data confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3682,   23,  238,   43,  190,   22,   61,   35,  680,   26],\n",
       "       [ 599, 2386,  284,  142,  452,   91,  205,   41,  670,  130],\n",
       "       [ 490,   19, 3332,  107,  652,  101,  122,   27,  137,   13],\n",
       "       [ 394,   53,  839, 2311,  549,  321,  302,   44,  169,   18],\n",
       "       [ 385,   16,  842,  146, 3227,   62,  106,   51,  154,   11],\n",
       "       [ 365,   34,  862,  542,  656, 2069,  261,   60,  138,   13],\n",
       "       [ 179,   26,  965,  251, 1044,  177, 2248,   13,   86,   11],\n",
       "       [ 399,   38,  679,  200, 1089,  159,  232, 2022,  143,   39],\n",
       "       [ 605,   71,  156,   77,  174,   68,   39,   15, 3763,   32],\n",
       "       [ 653,  331,  387,  204,  420,   95,  183,  130,  881, 1716]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Training data confusion matrix\n",
    "confusion_matrix(y_train_cifar, y_train_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test accuracy, and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy:  0.377\n",
      "\n",
      "No. of correct predictions (Test): 3770/10000\n",
      "\n",
      "Confusion Matrix (Test Data):\n",
      " [[582   9 101  10  49   7  25   7 195  15]\n",
      " [139 288  89  50 130  40  44  17 168  35]\n",
      " [145   5 456  54 206  30  55  13  34   2]\n",
      " [ 82  11 215 246 162 109 101  14  52   8]\n",
      " [ 92   4 259  40 489  18  43  14  40   1]\n",
      " [ 72   4 214 151 166 266  64  14  43   6]\n",
      " [ 36   4 259  74 285  27 288   1  25   1]\n",
      " [116  10 155  50 259  58  38 267  37  10]\n",
      " [154  20  47  33  43  17  10   6 662   8]\n",
      " [166  90  71  40  91  30  46  27 213 226]]\n",
      "Wall time: 18min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The accuracy of the model\n",
    "test_accuracy_knn = knn.score(X_test_cifar, y_test_cifar)\n",
    "print(\"\\nTest Accuracy: \", test_accuracy_knn)\n",
    "\n",
    "\n",
    "# No. of Correct Predictions\n",
    "y_test_predicted = knn.predict(X_test_cifar)\n",
    "print(\"\\nNo. of correct predictions (Test): %d/%d\" % (np.sum(y_test_predicted == y_test_cifar), len(y_test_cifar)))\n",
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test_cifar, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.58      0.45      1000\n",
      "           1       0.65      0.29      0.40      1000\n",
      "           2       0.24      0.46      0.32      1000\n",
      "           3       0.33      0.25      0.28      1000\n",
      "           4       0.26      0.49      0.34      1000\n",
      "           5       0.44      0.27      0.33      1000\n",
      "           6       0.40      0.29      0.34      1000\n",
      "           7       0.70      0.27      0.39      1000\n",
      "           8       0.45      0.66      0.54      1000\n",
      "           9       0.72      0.23      0.34      1000\n",
      "\n",
      "    accuracy                           0.38     10000\n",
      "   macro avg       0.46      0.38      0.37     10000\n",
      "weighted avg       0.46      0.38      0.37     10000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_cifar, y_test_predicted))\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain why your K-NN model was unable to obtain high test accuracy on the CIFAR-10 image classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inter-class distance is not significantly different from the intra-class distance for CIFAR-10 data. Compared to MNIST data, the background of CIFAR-10 data was not normalized and it is different from case to case. Besides, the larger variations of the shape of images in the same class also make it have lower test accuracy for CIFAR-10 data. There are a lot of variations in the background pixels across the images of the same object. Thus, a similarity-based approach (i.e., analogy-based approach), when applied pixel-wise, will not yield better performance to differentiate images belonging to different classes in the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why does a K-NN model perform excellent on the MNIST handwritten digits image classification problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reasons are the background pixels in the MNIST images follow a silimar pattern in all images belonging to the same class. In the MNIST dataset, there exists a global pattern in the pixel distribution of the same digit across all images of its categor. Images are normalized to have the same size and are centered for MNIST and there is less variation in the distribution of the pixels of the same class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
